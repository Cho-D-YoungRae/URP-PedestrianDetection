{"nbformat":4,"nbformat_minor":2,"metadata":{"accelerator":"GPU","colab":{"name":"baseline40.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1NbpRQ1AgJEfEjK7Iz-DGr9j57XqHMNXM","authorship_tag":"ABX9TyPEz4UrXy5lykk7ooKqc6ev"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e0683bc2322843c9b6ba890439e35552":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_78603be42125486f9e1fcf6993f125a4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_71fc81fbae4a42ea991f0a642d91b570","IPY_MODEL_675de78b17974f8c920918627bf46816"]}},"78603be42125486f9e1fcf6993f125a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71fc81fbae4a42ea991f0a642d91b570":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b69f2e36f8ec4e15bb069ce04e4d93a3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e28e541b610401db5de617151db68c3"}},"675de78b17974f8c920918627bf46816":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ef3cf5d561f4de0b1358f98104c91e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2252/? [11:00&lt;00:00,  3.41it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09b207e81ee04af387d3dbabc39f5f9c"}},"b69f2e36f8ec4e15bb069ce04e4d93a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2e28e541b610401db5de617151db68c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ef3cf5d561f4de0b1358f98104c91e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"09b207e81ee04af387d3dbabc39f5f9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","execution_count":1,"source":["%%capture\n","!pip install neptune-client psutil\n","!git clone https://github.com/Cho-D-YoungRae/URP_PD.git\n","%cd URP_PD\n","!pwd"],"outputs":[],"metadata":{"id":"W0TvU9YNsaS6","executionInfo":{"status":"ok","timestamp":1628419178590,"user_tz":-540,"elapsed":14195,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}}}},{"cell_type":"code","execution_count":2,"source":["import dataset\n","import object_detection\n","from utils import *\n","import eval\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.utils import make_grid\n","import torchvision.transforms.functional as TF\n","import torch.nn.functional as F\n","\n","import os\n","import json\n","import numpy as np\n","import argparse\n","from tqdm.auto import tqdm\n","import time\n","from datetime import datetime\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using <{device}> device\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.06s)\n","creating index...\n","index created!\n","Using <cuda> device\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4bO-I3EJ24N","executionInfo":{"status":"ok","timestamp":1628419180535,"user_tz":-540,"elapsed":1950,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}},"outputId":"5f18966e-6222-429e-e68a-35fb5a526edd"}},{"cell_type":"code","execution_count":3,"source":["# ====== constants ======#\n","label_map = {'background': 0, 'person': 1}\n","rev_label_map = {v: k for k, v in label_map.items()} "],"outputs":[],"metadata":{"id":"Y67SPUSaAECM","executionInfo":{"status":"ok","timestamp":1628419180536,"user_tz":-540,"elapsed":19,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}}}},{"cell_type":"markdown","source":["## setting"],"metadata":{"id":"EUCpxh6_XLYq"}},{"cell_type":"code","execution_count":4,"source":["from torch.backends import cudnn\n","import random\n","\n","cudnn.benchmark = True\n","\n","# ====== Random Seed Initialization ====== #\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","random.seed(seed)\n","\n","# torch.cuda.manual_seed(seed)\n","# torch.cuda.manual_seed_all(seed)\n","# torch.backends.cudnn.deterministic = True\n","# torch.backends.cudnn.benchmark = False\n","\n","parser = argparse.ArgumentParser()\n","args = parser.parse_args(\"\")\n","args.baselineID = 40\n","\n","# ====== Dataset ====== #\n","args.img_type = 'lwir'\n","args.val_split = 0.1\n","\n","# ====== Model ====== #\n","args.base_model = 'VGG16bnBase'\n","args.n_classes = len(label_map)\n","args.ch_option = {'num_ch': 1,\n","                  'img_type': 'lwir',\n","                  'one_ch_option': 'mean'\n","                  }\n","\n","\n","# ====== Optimizer & Training ====== #\n","args.optim = 'Adam'\n","args.lr = 5e-4\n","args.twice_b_lr = True\n","args.weight_decay = 5e-4\n","\n","args.epochs = 100\n","args.train_batch_size = 32\n","args.test_batch_size = 64\n","\n","args.decay_lr_at = [int(args.epochs/6)*4,\n","                    int(args.epochs/6)*5]\n","args.decay_lr_to = 0.1"],"outputs":[],"metadata":{"id":"TmVVX-18gDvl","executionInfo":{"status":"ok","timestamp":1628419180537,"user_tz":-540,"elapsed":14,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}}}},{"cell_type":"markdown","source":["## neptune init"],"metadata":{"id":"xntPJuloXPtB"}},{"cell_type":"code","execution_count":null,"source":["import neptune.new as neptune\n","\n","api_token = \n","run = neptune.init(\n","    project='jodyr/urp',\n","    source_files=['*.py'],\n","    api_token=api_token,\n","    run='PD-104',\n","    )\n","\n","run[\"parameters\"] = vars(args)\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["https://app.neptune.ai/jodyr/urp/e/PD-104\n","Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qswPKIZ-A_Ub","executionInfo":{"status":"ok","timestamp":1628418949140,"user_tz":-540,"elapsed":5614,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}},"outputId":"0b76476b-8ef6-47d8-cc75-e89e723e1206"}},{"cell_type":"markdown","source":["## copy-paste augmentation"],"metadata":{"id":"OXGE2b2xMfKn"}},{"cell_type":"code","execution_count":null,"source":["def limit_point_boundary(bbox, boundary=(0, 0, 300, 300)):\n","    for i in range(2):\n","        if bbox[i] < 0:\n","            bbox[i] = 0\n","    for i in range(2, 4):\n","        if bbox[i] > 300:\n","            bbox[i] = 300\n","\n","    return bbox\n","\n","def get_all_objects(images, bboxes):\n","    img_w, img_h = images.size(3), images.size(2)\n","    dims = torch.FloatTensor((img_w, img_h, img_w, img_h)).unsqueeze(0)\n","    bboxes = map(lambda x: torch.round(dims * x), bboxes)\n","    \n","    all_objects = []\n","    img_idx = []\n","    for i, (image, bboxes_in_img) in enumerate(zip(images, bboxes)):\n","        for bbox in bboxes_in_img:\n","            bbox = torch.round(bbox).long()\n","            x_min, y_min, x_max, y_max = limit_point_boundary(bbox)\n","            obj = image[:, y_min:y_max+1, x_min:x_max+1]\n","            img_idx.append(i)\n","            all_objects.append(obj)\n","\n","    return all_objects, img_idx"],"outputs":[],"metadata":{"id":"2GALTxKIs8qa"}},{"cell_type":"code","execution_count":null,"source":["def flip_objects(all_objects):\n","    for i in range(len(all_objects)):\n","        if random.random() < 0.5:\n","            all_objects[i] = torch.flip(all_objects[i], dims=(0, 2))\n","\n","    return all_objects"],"outputs":[],"metadata":{"id":"nhV_3jFoF0VR"}},{"cell_type":"code","execution_count":null,"source":["def get_to_imgs(img_idxs, batch_size):\n","    counts = [0] * batch_size\n","    for i in img_idxs:\n","        counts[i] += 1\n","    max_count, min_count = max(counts), min(counts)\n","    weights = [max_count - count + min_count for count in counts]\n","    to_imgs = random.choices(\n","        range(batch_size), weights=weights, k=len(img_idxs))\n","    \n","    return to_imgs"],"outputs":[],"metadata":{"id":"q967yEIcTYjU"}},{"cell_type":"code","execution_count":null,"source":["def copy_paste_aug(images, bboxes, category_ids,\n","                   max_paste_try=5,\n","                   resize_min_max=(0.8, 2),\n","                   max_overlap=0\n","                   ):\n","    batch_size, num_ch, img_h, img_w = images.size()\n","    img_dim = torch.Tensor([img_w, img_h, img_w, img_h])\n","    all_objects, img_idxs = get_all_objects(images, bboxes)\n","    all_objects = flip_objects(all_objects)\n","    to_imgs = get_to_imgs(img_idxs, batch_size)\n","\n","    for obj, to_img in zip(all_objects, to_imgs):\n","        _, obj_h, obj_w = obj.size()\n","        max_rescale = min(img_w / obj_w, img_h / obj_h)\n","        bboxes_in_img = bboxes[to_img]  # Tensor (n_objects, 4)\n","        cat_ids_in_img = category_ids[to_img]\n","        for _ in range(max_paste_try):\n","            rescale = random.uniform(*resize_min_max)\n","            rescale = min(rescale, max_rescale)\n","            r_h, r_w = int(rescale*obj_h), int(rescale*obj_w)\n","            r_h = 1 if r_h == 0 else r_h\n","            r_w = 1 if r_w == 0 else r_w\n","            resize_obj = F.interpolate(\n","                obj.unsqueeze(0), size=(r_h, r_w), mode='nearest'\n","            ).squeeze(0)\n","            paste_x = random.randint(0, img_w - r_w)\n","            paste_y = random.randint(0, img_h - r_h)\n","            paste_box = torch.Tensor(\n","                [paste_x, paste_y, paste_x+r_w, paste_y+r_h])   # (4,)\n","            scaled_paste_box = (paste_box / img_dim).unsqueeze(0)   # (1, 4)\n","            overlaps = find_jaccard_overlap(\n","                scaled_paste_box, bboxes_in_img\n","            )\n","            if overlaps.max().item() <= max_overlap:\n","                x_min, y_min, x_max, y_max = paste_box.long()\n","                images[to_img, :, y_min:y_max, x_min:x_max] = resize_obj\n","                bboxes_in_img = torch.cat((bboxes_in_img, scaled_paste_box))\n","                bboxes[to_img] = bboxes_in_img\n","                cat_ids_in_img = torch.cat((cat_ids_in_img,\n","                                           torch.LongTensor([1])))\n","                category_ids[to_img] = cat_ids_in_img\n","                break\n","            \n","\n","    return images, bboxes, category_ids"],"outputs":[],"metadata":{"id":"20KXnx4EUc_W"}},{"cell_type":"markdown","source":["## train"],"metadata":{"id":"vt5DJYIFXTGe"}},{"cell_type":"code","execution_count":null,"source":["def train(train_loader, model, criterion, optimizer):\n","    \"\"\"\n","    One epoch's training.\n","\n","    :param train_loader: DataLoader for training data\n","    :param model: model\n","    :param criterion: MultiBox loss\n","    :param optimizer: optimizer\n","    :param epoch: epoch number\n","    \"\"\"\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    model.train()  # training mode enables dropout\n","\n","    batch_time = AverageMeter()  # forward prop. + back prop. time\n","    data_time = AverageMeter()  # data loading time\n","    losses = AverageMeter()  # loss\n","\n","    print_freq = len(train_loader) // 4\n","\n","    start = time.time()\n","\n","    # Batches\n","    for i, (images, bboxes, category_ids, is_crowds) in enumerate(train_loader):\n","        data_time.update(time.time() - start)\n","        images, bboxes, category_ids = \\\n","            copy_paste_aug(images, bboxes, category_ids)\n","        images = images.to(device)  # (batch_size (N), 3, 300, 300)\n","        bboxes = [b.to(device) for b in bboxes]\n","        category_ids = [c.to(device) for c in category_ids]\n","\n","        # Forward prop.\n","        predicted_locs, predicted_scores = model(images)  # (N, 8732, 4), (N, 8732, n_classes)\n","\n","        # Loss\n","        loss = criterion(predicted_locs, predicted_scores, bboxes, category_ids)  # scalar\n","\n","        # Backward prop.\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # Update model\n","        optimizer.step()\n","\n","        losses.update(loss.item(), images.size(0))\n","        batch_time.update(time.time() - start)\n","\n","        start = time.time()\n","\n","        # Print status\n","        if i % print_freq == 0:\n","            print(f'[{i}/{len(train_loader)}]\\t'\n","                  f'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  f'Data Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  f'Loss {losses.val:.4f} ({losses.avg:.4f})\\t')\n","    del predicted_locs, predicted_scores, images, bboxes, category_ids\n","\n","    train_loss = losses.avg\n","    return train_loss        "],"outputs":[],"metadata":{"id":"H4paW5CDDjDw"}},{"cell_type":"markdown","source":["## validation"],"metadata":{"id":"oF1DPyDWXU96"}},{"cell_type":"code","execution_count":null,"source":["def validation(val_loader, model, criterion):\n","    model.eval()\n","\n","    num_batches = len(val_loader)\n","    losses = AverageMeter()\n","    with torch.no_grad():\n","        for i, (images, bboxes, category_ids, _) in enumerate(val_loader):\n","            images = images.to(device)\n","            bboxes = [b.to(device) for b in bboxes]\n","            category_ids = [l.to(device) for l in category_ids]\n","\n","            predicted_locs, predicted_scores = model(images)\n","            loss = criterion(predicted_locs, predicted_scores, bboxes, category_ids).item()\n","\n","            losses.update(loss, images.size(0))\n","\n","    val_loss = losses.avg\n","    return val_loss"],"outputs":[],"metadata":{"id":"VXfjlpR7Edzk"}},{"cell_type":"markdown","source":["## checkpoint"],"metadata":{"id":"P4Pu1TjpXYL8"}},{"cell_type":"code","execution_count":null,"source":["checkpoint = os.path.join('/content/drive/MyDrive/2021.summer_URP/PD/checkpoint',\n","                          str(args.baselineID)+'.pth.tar')\n","checkpoint = checkpoint if os.path.isfile(checkpoint) else None\n","print(f\"checkpoint: {checkpoint}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoint: /content/drive/MyDrive/2021.summer_URP/PD/checkpoint/40.pth.tar\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soKEyyLwJIAY","executionInfo":{"status":"ok","timestamp":1628418949148,"user_tz":-540,"elapsed":44,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}},"outputId":"c3465c92-1921-40f5-f0e2-2f53ab745610"}},{"cell_type":"code","execution_count":null,"source":["if checkpoint is None:\n","    start_epoch = 1\n","    lr = args.lr\n","    model = object_detection.SSD300(n_classes=args.n_classes,\n","                                    base=args.base_model,\n","                                    ch_option=args.ch_option)\n","    if args.twice_b_lr:\n","        biases = list()\n","        not_biases = list()\n","        for param_name, param in model.named_parameters():\n","            if param.requires_grad:\n","                if param_name.endswith('.bias'):\n","                    biases.append(param)\n","                else:\n","                    not_biases.append(param)\n","        optimizer = getattr(torch.optim, args.optim)(params=[{'params': biases, 'lr': 2 * lr}, \n","                                                            {'params': not_biases}],\n","                                                     lr=lr,\n","                                                     weight_decay=args.weight_decay)\n","    else:\n","        optimizer = getattr(torch.optim, args.optim)(params=model.parameters(),\n","                                                     lr=lr,\n","                                                     weight_decay=args.weight_decay)\n","\n","else:\n","    checkpoint = torch.load(checkpoint)\n","    start_epoch = checkpoint['epoch'] + 1\n","    print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n","    model = checkpoint['model']\n","    optimizer = checkpoint['optimizer']\n","\n","\n","model = model.to(device)\n","criterion = object_detection.MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(device)"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Loaded checkpoint from epoch 101.\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJSDeuA1FU5a","executionInfo":{"status":"ok","timestamp":1628418949153,"user_tz":-540,"elapsed":45,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}},"outputId":"1227e1bd-dca9-478b-ab26-8f0a453218c1"}},{"cell_type":"markdown","source":["## dataset init"],"metadata":{"id":"5dICzBxPXaSb"}},{"cell_type":"code","execution_count":null,"source":["workers = 4\n","train_dataset = dataset.KaistPDDataset()\n","train_loader = torch.utils.data.DataLoader(train_dataset, \n","                                           batch_size=args.train_batch_size, \n","                                           shuffle=True,\n","                                           collate_fn=dataset.collate_fn,\n","                                           num_workers=workers,\n","                                           pin_memory=True)"],"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"exf8bsQVX5T0","executionInfo":{"status":"ok","timestamp":1628418949154,"user_tz":-540,"elapsed":44,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}},"outputId":"d4ce1cbf-15c0-4735-825f-f251e6e7a589"}},{"cell_type":"markdown","source":["## experiment"],"metadata":{"id":"QxYiF3Sk7Ej7"}},{"cell_type":"code","execution_count":6,"source":["checkpoint_dir = '/content/drive/MyDrive/2021.summer_URP/PD/checkpoint'\n","checkpoint_path = os.path.join(checkpoint_dir,\n","                               str(args.baselineID)+'.pth.tar')"],"outputs":[],"metadata":{"id":"4n_a1BRPVbJ_","executionInfo":{"status":"ok","timestamp":1628419187913,"user_tz":-540,"elapsed":255,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}}}},{"cell_type":"code","execution_count":null,"source":["epochs = args.epochs\n","decay_lr_at = args.decay_lr_at\n","save_freq = 5\n","eval_freq = 10\n","\n","\n","# Epochs\n","for epoch in range(start_epoch, epochs+1):\n","    print(f\"# ====== Epoch {epoch} ====== # {datetime.now()}\")\n","    # Decay learning rate at particular epochs\n","    if epoch in decay_lr_at:\n","        adjust_learning_rate(optimizer, args.decay_lr_to)\n","\n","    # One epoch's training\n","    train_loss = train(train_loader=train_loader,\n","                       model=model,\n","                       criterion=criterion,\n","                       optimizer=optimizer)\n","    run['train/loss'].log(train_loss)\n","    if epoch % save_freq == 0:\n","        save_checkpoint(epoch, model, optimizer, checkpoint_path)\n","\n","    if epoch % eval_freq == 0:\n","        eval.evaluate(model, ch_option=args.ch_option)"],"outputs":[],"metadata":{"id":"H-YVHxnSIGee"}},{"cell_type":"code","execution_count":7,"source":["import eval\n","\n","checkpoint = torch.load(checkpoint_path)\n","save_epoch = checkpoint['epoch']\n","print(f'Loaded checkpoint from epoch {save_epoch}\\n')\n","model = checkpoint['model']\n","eval.evaluate(model,\n","              min_score=0.2,\n","              max_overlap=0.5,\n","              top_k=200)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded checkpoint from epoch 100\n","\n"]},{"output_type":"display_data","data":{"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"],"application/vnd.jupyter.widget-view+json":{"model_id":"e0683bc2322843c9b6ba890439e35552","version_minor":0,"version_major":2}},"metadata":{"tags":[]}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","/content/URP_PD/object_detection.py:395: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)\n","  image_boxes.append(class_decoded_locs[1 - suppress])\n","/content/URP_PD/object_detection.py:397: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)\n","  image_scores.append(class_scores[1 - suppress])\n"]},{"output_type":"stream","name":"stdout","text":["\n","Loading and preparing results...\n","DONE (t=0.02s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.39s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Miss Rate  (MR) @ Reasonable         [ IoU=0.50      | height=[55:10000000000] | visibility=[none+partial_occ] ] = 25.80%\n","Recall: 0.823404255319149\n"]}],"metadata":{"id":"ISVewxz02nLq","colab":{"base_uri":"https://localhost:8080/","height":409,"referenced_widgets":["e0683bc2322843c9b6ba890439e35552","78603be42125486f9e1fcf6993f125a4","71fc81fbae4a42ea991f0a642d91b570","675de78b17974f8c920918627bf46816","b69f2e36f8ec4e15bb069ce04e4d93a3","2e28e541b610401db5de617151db68c3","0ef3cf5d561f4de0b1358f98104c91e6","09b207e81ee04af387d3dbabc39f5f9c"]},"executionInfo":{"status":"ok","timestamp":1628419864647,"user_tz":-540,"elapsed":674941,"user":{"displayName":"조영래","photoUrl":"","userId":"09647157953709939310"}},"outputId":"732dc601-e2e5-40ab-992b-5d9cc5282d98"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"UqdfeCZBVYCh"}}]}